epochs: 10
num_class: 10
data_dir: 'numta'
output_dir: 'output'
train_batch: 128
valid_batch: 128
lr: 0.001
debug: true
model:
  - [Conv2D, [3, 16, 3, 1, 1]] # in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True
  - [ReLU, []] 
  - [MaxPool2D, [2, 2]]
  - [Conv2D, [16, 32, 3, 1, 1]] 
  - [ReLU, []] 
  - [MaxPool2D, [2, 2]]
  - [Conv2D, [32, 32, 3, 1, 1]] 
  - [ReLU, []]
  - [MaxPool2D, [2, 2]] 
  - [Flatten, []] 
  - [Linear, [1024]] # 
  - [ReLU, []] # 
  - [Linear, [512]] # 
  - [ReLU, []] # 
  - [Linear, [10]] #  
  - [Softmax, []]
augment:
  img_shape: [64, 64]
  use_bbox: true
  reverse: true
  aug: false
  dilation: false
  opening: false
  mixup: 0.5
  cache: true
lr_scheduler:
  factor: 0.7
  patience: 2
use_wandb: false
wandb:
  project: "cse472_cnn_scratch"
  entity: "nexh98" # anonymous
notebook: ''
name: 'Model1-Baseline'
comment: 'Model1-64x64'
exp: 'Baseline'



# model:
#   - [Conv2D, [3, 32, 5, 1]] # in_channels, out_channels, kernel_size, stride=1, padding=0, bias=True
#   - [ReLU, []] # (64 - 5)/1 + 1 = 60
#   - [Conv2D, [32, 64, 5, 2]] # 26
#   - [ReLU, []] # 26
#   - [MaxPool2D, [2, 2]] # kernel_size, stride=1 -> 13
#   - [Conv2D, [64, 64, 3, 1]] # (13 - 3) + 1 = 11
#   - [ReLU, []] # 11
#   - [Conv2D, [64, 64, 3, 2]] # (11 - 3)//2 + 1 = 5
#   - [ReLU, []] # 5
#   - [Flatten, []] # 64 * 5 * 5
#   - [Linear, [1600, 1024]] # 
#   - [ReLU, []] # 20
#   - [Linear, [1024, 512]]
#   - [ReLU, []] # 20
#   - [Linear, [512, 10]]
#   - [Softmax, []]
